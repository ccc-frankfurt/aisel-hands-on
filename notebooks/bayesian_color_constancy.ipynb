{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Bayesian color constancy\n",
    "\n",
    "In this notebook we follow the algorithm described in \"Bayesian Color Constancy for Outdoor Object Recognition\" by Tsin, Collins, Ramesh and Kanade.\n",
    "\n",
    "We are estimating the following values:\n",
    "* reflectance (sigma) per material\n",
    "* light spectrum (beta) per light source\n",
    "* material (o) per pixel\n",
    "* light source (w) per pixel\n",
    "* global illumination (g) per pixel\n",
    "\n",
    "### Algorithm:\n",
    "\n",
    "* find (sigma | o) and (beta | w) by LR decomposing labelled image patches\n",
    "* find mean color for each combination of (o, w)\n",
    "* for each pixel p:\n",
    "    * get distance to each (o,w) pair\n",
    "    * sort by distance\n",
    "    * init hypotheses o, w, sigma, g\n",
    "* for each light source w:\n",
    "    * get pixel with best hypothesis w\n",
    "    * estimate parameters for g(w)\n",
    "    * init spectrum\n",
    "* divide picture into windows\n",
    "* until no hypothesis remains:\n",
    "    * for each window:\n",
    "        * get pixels with best hypothesis w\n",
    "        * estimate parameters for g(w)\n",
    "        * for each pixel p:\n",
    "            * for each hypothesis H:\n",
    "                * update sigma\n",
    "                * update g\n",
    "    * for each pixel p:\n",
    "        * get likelihood\n",
    "    * update light spectrum for each w\n",
    "    * delete least likely hypothesis for each pixel\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# INPUTS:\n",
    "\n",
    "import glob\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "\n",
    "INDEX_BEST_HYPOTHESIS = 0\n",
    "\n",
    "NUM_COLORS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The following inputs are required and are currently set manually in code:\n",
    "* potential materials o\n",
    "* prior for each material\n",
    "* potential light sources w\n",
    "* prior for each light sourc\n",
    "* representative image regions for o\n",
    "* representative images w\n",
    "* table containing the mean color for each light source / material combination"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MATERIALS = [\"LEAF\",\n",
    "             \"CEMENT\",\n",
    "             \"PIPE\",\n",
    "             \"LID\"]\n",
    "NUM_MATERIALS = len(MATERIALS)\n",
    "p_o = np.ndarray((NUM_MATERIALS,))\n",
    "p_o[:] = 1. / NUM_MATERIALS # currently\n",
    "\n",
    "LIGHT_SOURCES = [\"DIRECT_LIGHT\",\n",
    "                 \"BRIGHT_LIGHT\"]\n",
    "NUM_LIGHT_SOURCES = len(LIGHT_SOURCES)\n",
    "p_w = np.ndarray((NUM_LIGHT_SOURCES,))\n",
    "p_w[:] = 1. / NUM_LIGHT_SOURCES\n",
    "\n",
    "\n",
    "# MAKE SURE ALL IMAGE REGIONS ARE THE SAME SIZE AND RELATIVELY SMALL (20 x 20)\n",
    "image_regions = {\n",
    "    \"LEAF\": ((220, 420), (250, 450)),\n",
    "    \"CEMENT\": ((80, 120), (110, 150)),\n",
    "    \"PIPE\": ((325, 520), (355, 550)),\n",
    "    \"LID\": ((0, 0), (30, 30)),\n",
    "}\n",
    "\n",
    "# MAKE SURE ALL EXAMPLE LIGHT SOURCE IMAGES ARE THE SAME SIZE\n",
    "image_light_sources = {\n",
    "    \"DIRECT_LIGHT\": [3, 5],\n",
    "    \"BRIGHT_LIGHT\": [2, 6]\n",
    "}\n",
    "\n",
    "MATERIALS_LIGHT_SOURCE_COMBINATIONS = list(itertools.product(range(NUM_MATERIALS), range(NUM_LIGHT_SOURCES)))\n",
    "NUM_HYPOTHESISES = len(MATERIALS_LIGHT_SOURCE_COMBINATIONS)\n",
    "MODEL_DIMENSIONS = 2  # can be increased to make everything more accurate\n",
    "\n",
    "sigma_p = np.diag([10, 10, 10]) # the correlation matrix between pixel values, can be obtained by running a seperate color calibration algorithm on the images.\n",
    "invered_sigma_p = np.linalg.inv(sigma_p)\n",
    "\n",
    "def get_mean_color_chart():\n",
    "    mean_color_chart = np.ndarray((NUM_MATERIALS, NUM_LIGHT_SOURCES, NUM_COLORS))\n",
    "\n",
    "    mean_color_chart[0, 0, :] = [92, 190, 120]\n",
    "    mean_color_chart[1, 0, :] = [150, 220, 215]\n",
    "    mean_color_chart[2, 0, :] = [80, 210, 240]\n",
    "    mean_color_chart[3, 0, :] = [30, 200, 210]\n",
    "\n",
    "    mean_color_chart[0, 1, :] = [250, 255, 255]\n",
    "    mean_color_chart[1, 1, :] = [255, 255, 255]\n",
    "    mean_color_chart[2, 1, :] = [210, 255, 255]\n",
    "    mean_color_chart[3, 1, :] = [65, 255, 250]\n",
    "\n",
    "    return mean_color_chart"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we build the distribution over the reflectance per material and the spectrum per light source."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def get_l_r_decomposition(image_data):\n",
    "    sample_image_patch = list(image_regions.values())[0]\n",
    "    patch_width = (sample_image_patch[0][0] - sample_image_patch[1][0])\n",
    "    patch_height = (sample_image_patch[0][1] - sample_image_patch[1][1])\n",
    "    num_pixel_in_patch = patch_width * patch_height\n",
    "\n",
    "    num_example_files = len(list(image_light_sources.values())[0])\n",
    "\n",
    "    Rs = np.ndarray((NUM_MATERIALS, NUM_LIGHT_SOURCES, NUM_COLORS * MODEL_DIMENSIONS, num_pixel_in_patch))\n",
    "    Ls = np.ndarray((NUM_MATERIALS, NUM_LIGHT_SOURCES, MODEL_DIMENSIONS, num_example_files))\n",
    "\n",
    "    for material_index, corners in enumerate(image_regions.values()):\n",
    "        p1, p2 = corners\n",
    "        for light_source_index, image_list in enumerate(image_light_sources.values()):\n",
    "            image_patch = image_data[image_list, p1[1]:p2[1], p1[0]:p2[0], :].reshape(num_example_files,\n",
    "                                                                                      3 * num_pixel_in_patch)\n",
    "            p, l, u = scipy.linalg.svd(image_patch, full_matrices=False)\n",
    "            R = u\n",
    "            L = p @ np.diag(l)\n",
    "            Rs[material_index, light_source_index, :, :] = R[0:MODEL_DIMENSIONS, :].reshape(\n",
    "                (3 * MODEL_DIMENSIONS, num_pixel_in_patch))\n",
    "            Ls[material_index, light_source_index, :, :] = L[0:MODEL_DIMENSIONS, :]\n",
    "\n",
    "    return Ls, Rs\n",
    "\n",
    "\n",
    "def estimate_sigma_distribution(Rs):\n",
    "    mu = np.ndarray((NUM_MATERIALS, MODEL_DIMENSIONS * NUM_COLORS))\n",
    "    cov = np.zeros((NUM_MATERIALS, MODEL_DIMENSIONS * NUM_COLORS, MODEL_DIMENSIONS * NUM_COLORS))\n",
    "\n",
    "    for o in range(NUM_MATERIALS):\n",
    "        values = Rs[o, :, :].T @ p_w[:]\n",
    "        mu[o, :, ] = values.mean(axis=0)\n",
    "        cov[o, :, :] = np.cov(values.T)\n",
    "    return mu, cov\n",
    "\n",
    "\n",
    "def estimate_beta_hats(Ls):\n",
    "    beta_hats = np.ndarray((NUM_LIGHT_SOURCES, MODEL_DIMENSIONS, NUM_FILES))\n",
    "\n",
    "    beta_hats[:, :, 0] = (Ls[:, :, :, :].T @ p_o).T.mean(axis=2)\n",
    "    for image_index in range(NUM_FILES):\n",
    "        beta_hats[:, :, image_index] = (Ls[:, :, :, :].T @ p_o).T[:, :, image_index % Ls.shape[3]]\n",
    "\n",
    "    return beta_hats / beta_hats.sum(axis=0)\n",
    "\n",
    "\n",
    "def estimate_beta_distribution(beta_hats):\n",
    "    mu = np.ndarray((NUM_LIGHT_SOURCES, MODEL_DIMENSIONS))\n",
    "    cov = np.ndarray((NUM_LIGHT_SOURCES, MODEL_DIMENSIONS, MODEL_DIMENSIONS))\n",
    "\n",
    "    for w in range(NUM_LIGHT_SOURCES):\n",
    "        values = beta_hats[w, :, :]\n",
    "        mu[w] = values.mean(axis=1)\n",
    "        cov[w] = np.cov(values)\n",
    "    return mu, cov\n",
    "\n",
    "# we are not interested in the actual angle, just the relative ordering, so no root of the value\n",
    "def color_angle_distance(color1, color2):\n",
    "    total = 0\n",
    "    for i in range(3):\n",
    "        total += (color1[i] - color2[i]) ** 2\n",
    "    return total\n",
    "\n",
    "\n",
    "def color_metric(color):\n",
    "    return math.sqrt(color_angle_distance([0, 0, 0], color))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we initialize all hypothesises (o/w pair) for all pixels with a value for the reflectance (sigma) and global illumination (g)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def init_pixel_hypothesises(img):\n",
    "    pixel_o = np.ndarray((NUM_PIXEL, NUM_HYPOTHESISES), dtype=\"uint8\")\n",
    "    pixel_w = np.ndarray((NUM_PIXEL, NUM_HYPOTHESISES), dtype=\"uint8\")\n",
    "    pixel_sigma = np.ndarray((NUM_PIXEL, NUM_HYPOTHESISES, MODEL_DIMENSIONS * 3))\n",
    "    pixel_g = np.ndarray((NUM_PIXEL, NUM_HYPOTHESISES))\n",
    "\n",
    "    for pi, pixel in enumerate(img[:, ]):\n",
    "        distances = [color_angle_distance(pixel, mean_color_chart[o, w, :]) for o, w in\n",
    "                     MATERIALS_LIGHT_SOURCE_COMBINATIONS]\n",
    "\n",
    "        # sort all hypothesises by descending likelihood\n",
    "        hypothesises = list(range(NUM_HYPOTHESISES))\n",
    "        hypothesises.sort(key=lambda i: distances[i])\n",
    "\n",
    "        for rank, h in enumerate(hypothesises):\n",
    "            o = MATERIALS_LIGHT_SOURCE_COMBINATIONS[h][0]\n",
    "            w = MATERIALS_LIGHT_SOURCE_COMBINATIONS[h][1]\n",
    "\n",
    "            pixel_o[pi, rank] = o\n",
    "            pixel_w[pi, rank] = w\n",
    "            pixel_sigma[pi, rank, :] = Rs[o, w, :, :].mean(axis=1)\n",
    "            pixel_g[pi, rank] = pixel @ mean_color_chart[o, w] / color_metric(mean_color_chart[o, w])\n",
    "\n",
    "    return pixel_o, pixel_w, pixel_sigma, pixel_g"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The function to estimate the global illumination (g) distribution per light source."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def estimate_g_distriution(g, w):\n",
    "    mu_g = np.ndarray((NUM_LIGHT_SOURCES,))\n",
    "    std_g = np.ndarray((NUM_LIGHT_SOURCES,))\n",
    "\n",
    "    for light_source in range(NUM_LIGHT_SOURCES):\n",
    "        mu_g[light_source] = 0\n",
    "        std_g[light_source] = 1\n",
    "\n",
    "        pixels_predicting_light_source = [i for i, w_hat in enumerate(w) if w_hat == light_source]\n",
    "        if len(pixels_predicting_light_source) != 0:\n",
    "            gw = np.array([g[i] for i in pixels_predicting_light_source])\n",
    "            mu_g[light_source] = gw.mean()\n",
    "            std_g[light_source] = np.std(gw)\n",
    "\n",
    "    return mu_g, std_g"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The reflectance for each pixel and each hypothesis is updated in the following function:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def update_sigma(sigma_p, g, beta, Sigma_o, mu_o, pixel):\n",
    "    # the matrizes should have the following dimensions:\n",
    "    # K1 : MODEL_DIMENSIONS x MODEL_DIMENSIONS\n",
    "    # K2 : MODEL_DIMENSIONS x 3\n",
    "    # K3 : 3 x 3\n",
    "\n",
    "    K3 = np.linalg.inv(sigma_p / g ** 2 + beta.T @ Sigma_o @ beta)\n",
    "    K2 = g * Sigma_o @ beta @ (np.eye(NUM_COLORS) - K3 @ beta.T @ Sigma_o @ beta)\n",
    "    K1 = np.eye(NUM_COLORS * MODEL_DIMENSIONS) - Sigma_o @ beta @ K3 @ beta.T\n",
    "\n",
    "    return K1 @ mu_o + K2 @ np.linalg.inv(sigma_p) @ pixel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After all pixel values were updated, we can update the distributions for the spectrum and the global illumination."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def update_betas(pixel_w, pixel_sigma, pixel_g, beta_distribution_mean, beta_distribution_std, sigma_p):\n",
    "    for light_source in range(NUM_LIGHT_SOURCES):\n",
    "        pixels_predicting_light_source = [i for i, w_hat in enumerate(pixel_w[:, INDEX_BEST_HYPOTHESIS])\n",
    "                                          if w_hat == light_source]\n",
    "        h = np.zeros((MODEL_DIMENSIONS, MODEL_DIMENSIONS))\n",
    "        b = np.zeros((MODEL_DIMENSIONS,))\n",
    "\n",
    "        mu_beta = beta_distribution_mean[light_source, :]\n",
    "        Sigma_beta = beta_distribution_std[light_source, :, :]\n",
    "        Sigma_beta_inv = np.linalg.inv(Sigma_beta)\n",
    "\n",
    "        # in case of large images, sampling from pixels_predicting_light_source will provide a speedup\n",
    "        # like: pixels_predicting_light_source = pixels_predicting_light_source[::N]\n",
    "\n",
    "        for pi in pixels_predicting_light_source:\n",
    "            S = pixel_sigma[pi, 0].reshape((MODEL_DIMENSIONS, NUM_COLORS))\n",
    "            pixel = img[pi, :]\n",
    "\n",
    "            h += (pixel_g[pi, 0] ** 2) * S @ sigma_p @ S.T\n",
    "            b += pixel_g[pi, 0] * S @ sigma_p @ pixel\n",
    "\n",
    "        h += len(pixels_predicting_light_source) * Sigma_beta_inv\n",
    "        b += len(pixels_predicting_light_source) * (Sigma_beta_inv @ mu_beta)\n",
    "\n",
    "        beta_hats[light_source, :, image_index] = np.linalg.inv(h) @ b\n",
    "\n",
    "    return beta_hats\n",
    "\n",
    "def update_g(mu_g, cov_g, pixel, inverted_sigma_p, S, beta):\n",
    "    g_nom = (mu_g[w] + cov_g[w] ** 2 * pixel @ inverted_sigma_p @ S.T @ beta)\n",
    "    g_denom = (1 + (cov_g[w] ** 2) * beta @ S @ inverted_sigma_p @ S.T @ beta)\n",
    "\n",
    "    return g_nom / g_denom"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After all new values are calculated, we get the likelihood for each hypothesis for each pixel.\n",
    "Since the values get small, log-likelihood is used instead."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def log_N_multidim(value, mu, cov):\n",
    "    dims = cov.shape[0]\n",
    "    return -dims / 2 * math.log(2 * math.pi) - 0.5 * math.log(abs(np.linalg.det(cov))) \\\n",
    "           + (-0.5 * ((value - mu).T @ np.linalg.inv(cov) @ (value - mu)))\n",
    "\n",
    "\n",
    "def log_N_singledim(value, mu, std):\n",
    "    return -0.5 * math.log(2 * math.pi) - 0.5 * std \\\n",
    "           + (-0.5 * (1 / std) * (value - mu) ** 2)\n",
    "\n",
    "\n",
    "def calc_log_likelihoods(img, num_hypothesises_remaining):\n",
    "    # p(p|S,beta, g) * p(beta|w) * p(S|o) * p(g|w) * p(w) * p(o)\n",
    "\n",
    "    likelihoods = np.ndarray((NUM_PIXEL, num_hypothesises_remaining))\n",
    "    for pi, pixel in enumerate(img[:, ]):\n",
    "        for hi in range(num_hypothesises_remaining):\n",
    "            o = pixel_o[pi, hi]\n",
    "            w = pixel_w[pi, hi]\n",
    "\n",
    "            S = pixel_sigma[pi, hi].reshape((MODEL_DIMENSIONS, NUM_COLORS))\n",
    "\n",
    "            p_p = log_N_multidim(pixel,\n",
    "                                 pixel_g[pi, hi] * S.T @ beta_hats[w, :, image_index],\n",
    "                                 sigma_p)\n",
    "            p_S = log_N_multidim(pixel_sigma[pi, hi, :],\n",
    "                                 sigma_distribution_mean[o, :],\n",
    "                                 sigma_distribution_std[o])\n",
    "            p_g = log_N_singledim(pixel_g[pi, hi],\n",
    "                                  mu_g[w],\n",
    "                                  std_g[w])\n",
    "            p_beta = log_N_multidim(beta_hats[w, :, image_index],\n",
    "                                    beta_distribution_mean[w],\n",
    "                                    beta_distribution_std[w])\n",
    "            likelihoods[pi, hi] = p_p + p_beta + p_S + p_g + p_w[w] + p_o[o]\n",
    "\n",
    "    return likelihoods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We remove the least likely hypothesis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def update_hypothesises(likelihoods, pixel_o, pixel_w, pixel_sigma, pixel_g):\n",
    "    num_hypothesises_remaining = pixel_o.shape[1]\n",
    "\n",
    "    pixel_o_new = np.ndarray((NUM_PIXEL, num_hypothesises_remaining - 1), dtype=\"uint8\")\n",
    "    pixel_w_new = np.ndarray((NUM_PIXEL, num_hypothesises_remaining - 1), dtype=\"uint8\")\n",
    "    pixel_sigma_new = np.ndarray((NUM_PIXEL, num_hypothesises_remaining - 1, MODEL_DIMENSIONS * NUM_COLORS))\n",
    "    pixel_g_new = np.ndarray((NUM_PIXEL, num_hypothesises_remaining - 1))\n",
    "\n",
    "    for pi in range(NUM_PIXEL):\n",
    "        # update arrays sorted by likelihood\n",
    "        sorted_likelihoods = list(range(num_hypothesises_remaining))\n",
    "        sorted_likelihoods = list(sorted(sorted_likelihoods, key=lambda i: likelihoods[pi, i]))[:-1]\n",
    "\n",
    "        pixel_o_new[pi, :] = pixel_o[pi, sorted_likelihoods]\n",
    "        pixel_w_new[pi, :] = pixel_w[pi, sorted_likelihoods]\n",
    "        pixel_sigma_new[pi, :] = pixel_sigma[pi, sorted_likelihoods]\n",
    "        pixel_g_new[pi, :] = pixel_g[pi, sorted_likelihoods]\n",
    "\n",
    "    return pixel_o_new, pixel_w_new, pixel_sigma_new, pixel_g_new\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A function for writing the segmented image for each material or light source."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def write_segmented_image(region_x, region_y, mask, filename):\n",
    "    masked = np.zeros((NUM_PIXEL, NUM_COLORS))\n",
    "    masked[mask, :] = [255, 255, 255]\n",
    "    masked = masked.reshape((IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
    "    masked = masked[region_y[0]:region_y[1], region_x[0]:region_x[1], :]\n",
    "    cv2.imwrite(filename, masked)\n",
    "\n",
    "\n",
    "def flatten_indizes(x_start, x_end, y_start, y_end, width):\n",
    "    return [py * width + px\n",
    "            for px in range(x_start, x_end)\n",
    "            for py in range(y_start, y_end)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Putting it all together. Load a folder full of images, initialize hypothesises and iterate until there is only one hypothesis left."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_images_from_folder(pattern):\n",
    "    files = glob.glob(pattern)\n",
    "    num_files = len(files)\n",
    "\n",
    "    img = cv2.imread(files[0])\n",
    "\n",
    "    data = np.ndarray((num_files, img.shape[0], img.shape[1], 3))\n",
    "    for i, f in enumerate(files):\n",
    "        img = cv2.imread(f)\n",
    "        data[i, :, :, :] = img[:, :, :]\n",
    "    return data\n",
    "\n",
    "print(\"START\")\n",
    "\n",
    "image_data = get_images_from_folder(\"../data/cropped_plants/*.jpg\")\n",
    "\n",
    "NUM_FILES = image_data.shape[0]\n",
    "IMAGE_HEIGHT = image_data.shape[1]\n",
    "IMAGE_WIDTH = image_data.shape[2]\n",
    "NUM_PIXEL = image_data.shape[1] * image_data.shape[2]\n",
    "\n",
    "print(\"SVD DECOMPOSITION OF IMAGE PATCHES\")\n",
    "\n",
    "Ls, Rs = get_l_r_decomposition(image_data)\n",
    "sigma_distribution_mean, sigma_distribution_std = estimate_sigma_distribution(Rs)\n",
    "beta_hats = estimate_beta_hats(Ls)\n",
    "beta_distribution_mean, beta_distribution_std = estimate_beta_distribution(beta_hats)\n",
    "\n",
    "print(\"FIND MEAN COLOR FOR EACH COMBINATION OF MATERIAL AND LIGHT SOURCE\")\n",
    "\n",
    "mean_color_chart = get_mean_color_chart()\n",
    "\n",
    "# for now, only work on a single image\n",
    "for image_index, f in enumerate([\"../data/cropped_plants/1604404802.jpg\"]):\n",
    "    filename = os.path.splitext(os.path.basename(f))[0]\n",
    "    img = cv2.imread(f)\n",
    "    img = img.reshape((NUM_PIXEL, NUM_COLORS))\n",
    "    img_width = IMAGE_WIDTH\n",
    "    img_height = IMAGE_HEIGHT\n",
    "\n",
    "    print(f\"{f} INIT PIXEL HYPOTHESISES\")\n",
    "\n",
    "    pixel_o, pixel_w, pixel_sigma, pixel_g = init_pixel_hypothesises(img)\n",
    "\n",
    "    print(f\"{f} INIT LIGHT SOURCE HYPOTHESISES\")\n",
    "\n",
    "    mu_g, std_g = estimate_g_distriution(pixel_g[:, INDEX_BEST_HYPOTHESIS], pixel_w[:, INDEX_BEST_HYPOTHESIS])\n",
    "\n",
    "    print(f\"{f} ITERATE OVER IMAGE WINDOWS\")\n",
    "\n",
    "    # we take a part of the image (the macro region) and slide over it in overlapping windows\n",
    "    # the windows should overlap a bit, the amount is set here\n",
    "    MACRO_REGION_X = (0, 600)\n",
    "    MACRO_REGION_Y = (000, 600)\n",
    "    WINDOW_X_SIZE = 50\n",
    "    WINDOW_Y_SIZE = 50\n",
    "    OVERLAPPING = 25\n",
    "\n",
    "    for iteration in range(NUM_HYPOTHESISES - 1):\n",
    "        num_hypothesises_remaining = NUM_HYPOTHESISES - iteration\n",
    "\n",
    "        print(f\"{f} Run {iteration + 1} / {NUM_HYPOTHESISES - 1}\")\n",
    "\n",
    "        for window_x in range(MACRO_REGION_X[0], MACRO_REGION_X[1] + 1, WINDOW_X_SIZE - OVERLAPPING):\n",
    "            for window_y in range(MACRO_REGION_Y[0], MACRO_REGION_Y[1] + 1, WINDOW_X_SIZE - OVERLAPPING):\n",
    "                pixel_indizes_patch = flatten_indizes(window_x, min(window_x + WINDOW_X_SIZE, img_width),\n",
    "                                                      window_y, min(window_y + WINDOW_Y_SIZE, img_height),\n",
    "                                                      img_width)\n",
    "\n",
    "                mu_g_patch, std_g_patch = estimate_g_distriution(pixel_g[pixel_indizes_patch, INDEX_BEST_HYPOTHESIS],\n",
    "                                                                 pixel_w[pixel_indizes_patch, INDEX_BEST_HYPOTHESIS])\n",
    "\n",
    "                for pi in pixel_indizes_patch:\n",
    "                    pixel = img[pi]\n",
    "\n",
    "                    for hi in range(num_hypothesises_remaining):\n",
    "                        w = pixel_w[pi, hi]\n",
    "                        o = pixel_o[pi, hi]\n",
    "                        S = pixel_sigma[pi, hi].reshape((MODEL_DIMENSIONS, NUM_COLORS))\n",
    "\n",
    "                        beta_old = beta_hats[w, :, image_index]\n",
    "\n",
    "                        # pad the beta values into a larger matrix\n",
    "                        beta_matrix = np.zeros((NUM_COLORS * MODEL_DIMENSIONS, NUM_COLORS))\n",
    "                        for i in range(NUM_COLORS):\n",
    "                            beta_matrix[i * MODEL_DIMENSIONS:(i + 1) * MODEL_DIMENSIONS, i] = beta_old\n",
    "\n",
    "                        pixel_sigma[pi, hi] = update_sigma(sigma_p, pixel_g[pi, hi], beta_matrix,\n",
    "                                                           sigma_distribution_std[o, :, :], sigma_distribution_mean[o],\n",
    "                                                           pixel)\n",
    "\n",
    "                        pixel_g[pi, hi] = update_g(mu_g_patch, std_g_patch, pixel, invered_sigma_p, S, beta_old)\n",
    "\n",
    "        likelihoods = calc_log_likelihoods(img, num_hypothesises_remaining)\n",
    "\n",
    "        beta_hats = update_betas(pixel_w, pixel_sigma, pixel_g, beta_distribution_mean, beta_distribution_std, sigma_p)\n",
    "\n",
    "        pixel_o, pixel_w, pixel_sigma, pixel_g = update_hypothesises(likelihoods, pixel_o, pixel_w, pixel_sigma,\n",
    "                                                                     pixel_g)\n",
    "\n",
    "        for o in range(NUM_MATERIALS):\n",
    "            write_segmented_image(MACRO_REGION_X, MACRO_REGION_Y, [pi for pi in range(NUM_PIXEL) if pixel_o[pi, INDEX_BEST_HYPOTHESIS] == o],\n",
    "                                  f\"{filename}_masked_by_object_{MATERIALS[o]}_{iteration}.png\")\n",
    "\n",
    "        for w in range(NUM_LIGHT_SOURCES):\n",
    "            write_segmented_image(MACRO_REGION_X, MACRO_REGION_Y, [pi for pi in range(NUM_PIXEL) if pixel_w[pi, INDEX_BEST_HYPOTHESIS] == w],\n",
    "                                  f\"{filename}_masked_by_lightsource_{LIGHT_SOURCES[w]}_{iteration}.png\")\n",
    "\n",
    "    print(f\"{f} PRINT SEGMENTED IMAGES\")\n",
    "\n",
    "    ll_image = likelihoods[:, INDEX_BEST_HYPOTHESIS].reshape((img_height, img_width))\n",
    "    ll_image_region = ll_image[MACRO_REGION_Y[0]:MACRO_REGION_Y[1], MACRO_REGION_X[0]:MACRO_REGION_X[1]]\n",
    "    plt.imshow(ll_image_region, cmap=\"hot\")\n",
    "    plt.show()\n",
    "\n",
    "    leaf_likelihoods = likelihoods[[i for i in range(NUM_PIXEL) if pixel_o[i, INDEX_BEST_HYPOTHESIS] == 0], 0]\n",
    "    plt.hist(leaf_likelihoods, bins=100, cumulative=True)\n",
    "    plt.show()\n",
    "\n",
    "print(\"END\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}